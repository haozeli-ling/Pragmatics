# Informativeness in RSA

$\text{Utility}'(u, s) = \text{ln} (P_{L_0}(s \mid u)) - \text{Cost}'(u)$

--- 

### Additivity of Information 

The logarithm is **intimately connected to information theory**, where it measures **information content** or **surprisal**. 

**Surprisal** = $-\ln P_{L_0}(s \mid u)$

- A **higher probability** $\(P_{L_0}(s \mid u)\)$ means **less surprisal** (less information is gained because the outcome is predictable).
- A **lower probability** means **more surprisal** (more information is gained because the outcome is unexpected).

Using $\ln P_{L_0}(s \mid u)$ in the utility function means the speaker is reasoning in terms of **information gain**, emphasizing how much information the utterance conveys to the listener.

#### Additivity

Logarithms turn probabilities (which are multiplicative) into additive values. This simplifies calculations in recursive reasoning. This additivity aligns with how information accumulates across multiple utterances, making it easier to combine contributions from multiple factors.

- If two events occur **independently**, their joint probability is $P(A, B) = P(A) \cdot P(B)$.
- Taking the log makes this additive: $\ln P(A, B) = \ln P(A) + \ln P(B)$.

---

### **Concrete Example: Interpreting Two Consecutive Utterances in RSA**  

#### **Scenario: A Listener Interpreting a Speaker's Intent**
Imagine a speaker describes an object in a scene where the target object is a **blue square**, and the listener is reasoning about its identity.  

##### **Step 1: Prior Beliefs About Objects in the Scene**
The listener starts with a **prior probability** for each object being the referent:  

| Object        | Prior Probability \( P(s) \) |
|--------------|--------------------|
| **Blue Square**  | 0.5 |
| **Blue Circle**  | 0.3 |
| **Red Square**  | 0.2 |

Taking the **logarithm** of these probabilities gives **log-probabilities**, which are **additive**:  

| Object        | \( \log P(s) \) |
|--------------|--------------|
| **Blue Square**  | \( \log 0.5 = -0.301 \) |
| **Blue Circle**  | \( \log 0.3 = -0.523 \) |
| **Red Square**  | \( \log 0.2 = -0.699 \) |

---

##### **Step 2: First Utterance – "Blue"**  
The speaker says **"Blue"**, and the listener updates their belief about the referent.  

**Likelihood of Speaker Choosing "Blue" Given Each Object:**  

| Object        | \( P(w = \text{"Blue"} \mid s) \) |
|--------------|----------------------------|
| **Blue Square**  | 0.8 |
| **Blue Circle**  | 0.7 |
| **Red Square**  | 0.1 |

Instead of multiplying probabilities, we convert them into **log-space** (logarithms turn multiplication into addition):  

| Object        | \( \log P(w \mid s) \) |
|--------------|------------------|
| **Blue Square**  | \( \log 0.8 = -0.097 \) |
| **Blue Circle**  | \( \log 0.7 = -0.155 \) |
| **Red Square**  | \( \log 0.1 = -1.000 \) |

Now, we **add** these log-values to the prior log-probabilities:  

| Object        | Updated Log-Probability |
|--------------|------------------|
| **Blue Square**  | \( -0.301 + (-0.097) = -0.398 \) |
| **Blue Circle**  | \( -0.523 + (-0.155) = -0.678 \) |
| **Red Square**  | \( -0.699 + (-1.000) = -1.699 \) |

After exponentiating and normalizing, the updated probabilities are:  

| Object        | Updated Probability |
|--------------|------------------|
| **Blue Square**  | 0.54 |
| **Blue Circle**  | 0.40 |
| **Red Square**  | 0.06 |

---

##### **Step 3: Second Utterance – "Square"**  
Now, the speaker follows up with **"Square"**, further refining the listener’s understanding.  

**Likelihoods for "Square":**  

| Object        | \( P(w = \text{"Square"} \mid s) \) |
|--------------|----------------------------|
| **Blue Square**  | 0.9 |
| **Blue Circle**  | 0.1 |
| **Red Square**  | 0.8 |

Converted to **log-space**:  

| Object        | \( \log P(w \mid s) \) |
|--------------|------------------|
| **Blue Square**  | \( \log 0.9 = -0.046 \) |
| **Blue Circle**  | \( \log 0.1 = -1.000 \) |
| **Red Square**  | \( \log 0.8 = -0.097 \) |

Adding these to the previously updated log-values:  

| Object        | Final Log-Probability |
|--------------|------------------|
| **Blue Square**  | \( -0.398 + (-0.046) = -0.444 \) |
| **Blue Circle**  | \( -0.678 + (-1.000) = -1.678 \) |
| **Red Square**  | \( -1.699 + (-0.097) = -1.796 \) |

After exponentiating and normalizing, we get:  

| Object        | Final Probability |
|--------------|------------------|
| **Blue Square**  | 0.88 |
| **Blue Circle**  | 0.08 |
| **Red Square**  | 0.04 |

---

### Relative differences & diminishing returns

Logarithms emphasize **relative differences** between probabilities, particularly when they are small. 

- The difference between $P(u) = 0.9$ and $P(u) = 0.8$ (large probabilities) represent high-likelihood events, so their difference feels less important in terms of informativeness compared to the difference between $P(u) = 0.2$ and $P(u) = 0.1$ (small probabilities), which represent low-likelihood events.
- Using $\ln$ reflects this intuition, as differences in smaller probabilities are stretched, giving them greater weight.

  - For $P(u) = 0.9$, $-\ln(0.9) \approx 0.105$; for $P(u) = 0.8$, $-\ln(0.8) \approx 0.223$; the difference between $P(u) = 0.9$ and $P(u) = 0.8$ is $(0.223 - 0.105) = 0.118$
  - For $P(u) = 0.2$, $-\ln(0.2) \approx 1.609$; for $P(u) = 0.1$, $-\ln(0.1) \approx 2.302$; the difference between $P(u) = 0.9$ and $P(u) = 0.8$ is $(2.302 - 1.609) = 0.693$

Logarithms reflect **diminishing returns**, which aligns with human intuition about utility. 

- If the probability of an event increases from \(0.01\) to \(0.1\), the increase in informativeness is substantial.
- If the probability increases from \(0.8\) to \(0.9\), the informativeness increase is much smaller.

In the RSA framework, this property is crucial because:

- High-probability utterances: Convey less new information and are less valuable in distinguishing between possible situations.
- Low-probability utterances: May be surprising but are often more informative, as they narrow down the listener’s interpretation more effectively.

  > **Example**: Suppose you are live in Singapore, ... <br>
  > $u_1 =$ 'it will rain today': $P(u_1) = 0.8$. Hearing this adds little new information since you already expect rain. <br>
  > $u_2 =$ 'It will snow today': $P(u_2) = 0.1$. Hearing this is much more surprising and informative. 

This makes $\ln P_{L_0}(s \mid u)$ more sensitive to **informative but less likely utterances**, which might play a critical role in communication. The diminishing returns property ensures that the utility function doesn't overemphasize small changes in already-high probabilities. It captures the fact that once an utterance is very informative, there's less incentive to make it even more precise.

---

### Summary of using $\ln(P)$:
1. **Captures Information Content:** Reflects the surprisal of events in a way consistent with information theory.
2. **Additivity:** Makes combining multiple probabilities easier by turning products into sums.
3. **Relative Emphasis:** Highlights differences in small probabilities, making the model sensitive to low-probability but informative utterances.
4. **Diminishing Returns:** Models how informativeness increases more significantly at lower probabilities.

